{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "* Within a 24-hour period and for a specific remote unit, are entries and exits ever not equal? If so, under what circumstances is this the case?\n",
    "\n",
    "* How does ridership correlate with rainy weather?\n",
    "\n",
    "* How does ridership correlate with temperature?\n",
    "\n",
    "* How does ridership change throughout the day?\n",
    "\n",
    "* How does ridership change throughout the week?\n",
    "\n",
    "* Which station has the highest average number of riders per day? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Two-Dimensional Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2342.5999999999999, 3239.9000000000001)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership = np.array([\n",
    "    [   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Accessing elements\n",
    "if False:\n",
    "    print ridership[1, 3]\n",
    "    print ridership[1:3, 3:5]\n",
    "    print ridership[1, :]\n",
    "    \n",
    "# Vectorized operations on rows or columns\n",
    "if False:\n",
    "    print ridership[0, :] + ridership[1, :]\n",
    "    print ridership[:, 0] + ridership[:, 1]\n",
    "    \n",
    "# Vectorized operations on entire arrays\n",
    "if False:\n",
    "    a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "    b = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "    print a + b\n",
    "\n",
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "    \n",
    "    Hint: NumPy's argmax() function might be useful:\n",
    "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html\n",
    "    '''\n",
    "    max_station_index = ridership[0, :].argmax()\n",
    "    mean_for_max = ridership[:, max_station_index].mean()\n",
    "    \n",
    "    overall_mean = ridership.mean()\n",
    "    \n",
    "    return (overall_mean, mean_for_max)\n",
    "    \n",
    "print mean_riders_for_max_station(ridership)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Numpy Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3239.9000000000001, 1071.2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# NumPy axis argument\n",
    "if False:\n",
    "    a = np.array([\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9]\n",
    "    ])\n",
    "    \n",
    "    print a.sum()\n",
    "    print a.sum(axis=0)\n",
    "    print a.sum(axis=1)\n",
    "    \n",
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership = np.array([\n",
    "    [   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])\n",
    "\n",
    "def min_and_max_riders_per_day(ridership):\n",
    "    '''\n",
    "    Fill in this function. First, for each subway station, calculate the\n",
    "    mean ridership per day. Then, out of all the subway stations, return the\n",
    "    maximum and minimum of these values. That is, find the maximum\n",
    "    mean-ridership-per-day and the minimum mean-ridership-per-day for any\n",
    "    subway station.\n",
    "    '''\n",
    "    mean_per_day = ridership.mean(axis=0)\n",
    "    \n",
    "    max_daily_ridership = mean_per_day.max()     # Replace this with your code\n",
    "    min_daily_ridership = mean_per_day.min()     # Replace this with your code\n",
    "    \n",
    "    return (max_daily_ridership, min_daily_ridership)\n",
    "    \n",
    "print min_and_max_riders_per_day(ridership)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6: Accessing Elements of a Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          R004  R005  R006\n",
      "05-01-11     0     2     5\n",
      "05-02-11  3877  3674  2328\n",
      "05-03-11  4088  3991  6461\n",
      "(2342.6000000000004, 3239.9000000000001)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership_df = pd.DataFrame(\n",
    "    data=[[   0,    0,    2,    5,    0],\n",
    "          [1478, 3877, 3674, 2328, 2539],\n",
    "          [1613, 4088, 3991, 6461, 2691],\n",
    "          [1560, 3392, 3826, 4787, 2613],\n",
    "          [1608, 4802, 3932, 4477, 2705],\n",
    "          [1576, 3933, 3909, 4979, 2685],\n",
    "          [  95,  229,  255,  496,  201],\n",
    "          [   2,    0,    1,   27,    0],\n",
    "          [1438, 3785, 3589, 4174, 2215],\n",
    "          [1342, 4043, 4009, 4665, 3033]],\n",
    "    index=['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "           '05-06-11', '05-07-11', '05-08-11', '05-09-11', '05-10-11'],\n",
    "    columns=['R003', 'R004', 'R005', 'R006', 'R007']\n",
    ")\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# DataFrame creation\n",
    "if False:\n",
    "    # You can create a DataFrame out of a dictionary mapping column names to values\n",
    "    df_1 = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "    print df_1\n",
    "\n",
    "    # You can also use a list of lists or a 2D NumPy array\n",
    "    df_2 = pd.DataFrame([[0, 1, 2], [3, 4, 5]], columns=['A', 'B', 'C'])\n",
    "    print df_2\n",
    "   \n",
    "\n",
    "# Accessing elements\n",
    "if False:\n",
    "    print ridership_df.iloc[0]\n",
    "    print ridership_df.loc['05-05-11']\n",
    "    print ridership_df['R003']\n",
    "    print ridership_df.iloc[1, 3]\n",
    "    \n",
    "# Accessing multiple rows\n",
    "if False:\n",
    "    print ridership_df.iloc[1:4]\n",
    "    \n",
    "# Accessing multiple columns\n",
    "if False:\n",
    "    print ridership_df[['R003', 'R005']]\n",
    "    \n",
    "# Pandas axis\n",
    "if False:\n",
    "    df = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "    print df.sum()\n",
    "    # print df.sum(axis=1)\n",
    "    # print df.values.sum()\n",
    "    \n",
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "\n",
    "    This is the same as a previous exercise, but this time the\n",
    "    input is a Pandas DataFrame rather than a 2D NumPy array.\n",
    "    '''\n",
    "    overall_mean = ridership.mean(axis=1).values.mean()\n",
    "    \n",
    "    column = ridership.iloc[0].argmax()\n",
    "    mean_for_max = ridership[column].mean()\n",
    "\n",
    "    return (overall_mean, mean_for_max)\n",
    "\n",
    "print mean_riders_for_max_station(ridership_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3.8: Calculating Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0356485157722\n",
      "-0.0266933483216\n",
      "-0.229034323408\n",
      "0.585895470766\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = 'nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "def correlation(x, y):\n",
    "    '''\n",
    "    Fill in this function to compute the correlation between the two\n",
    "    input variables. Each input is either a NumPy array or a Pandas\n",
    "    Series.\n",
    "    \n",
    "    correlation = average of (x in standard units) times (y in standard units)\n",
    "    \n",
    "    Remember to pass the argument \"ddof=0\" to the Pandas std() function!\n",
    "    '''\n",
    "    x_mean = x.mean()\n",
    "    y_mean = y.mean()\n",
    "    \n",
    "    x_std = x.std(ddof=0)\n",
    "    y_std = y.std(ddof=0)\n",
    "    \n",
    "    x_standard_score = (x-x_mean)/x_std\n",
    "    y_standard_score = (y-y_mean)/y_std\n",
    "    \n",
    "    correlation_coefficient = sum(x_standard_score * y_standard_score) / len(x)\n",
    "    \n",
    "    return correlation_coefficient\n",
    "\n",
    "entries = subway_df['ENTRIESn_hourly']\n",
    "cum_entries = subway_df['ENTRIESn']\n",
    "rain = subway_df['meanprecipi']\n",
    "temp = subway_df['meantempi']\n",
    "\n",
    "print correlation(entries, rain)\n",
    "print correlation(entries, temp)\n",
    "print correlation(rain, temp)\n",
    "\n",
    "print correlation(entries, cum_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.10: DataFrame Vectorized Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ENTRIESn  EXITSn\n",
      "0       NaN     NaN\n",
      "1      23.0     8.0\n",
      "2      18.0    18.0\n",
      "3      71.0    54.0\n",
      "4     170.0    44.0\n",
      "5     214.0    42.0\n",
      "6      87.0    11.0\n",
      "7      10.0     3.0\n",
      "8      36.0    89.0\n",
      "9     153.0   333.0\n",
      "   ENTRIESn  EXITSn\n",
      "0       NaN     NaN\n",
      "1      23.0     8.0\n",
      "2      18.0    18.0\n",
      "3      71.0    54.0\n",
      "4     170.0    44.0\n",
      "5     214.0    42.0\n",
      "6      87.0    11.0\n",
      "7      10.0     3.0\n",
      "8      36.0    89.0\n",
      "9     153.0   333.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Examples of vectorized operations on DataFrames:\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Adding DataFrames with the column names\n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "    df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]})\n",
    "    print df1 + df2\n",
    "\n",
    "# Adding DataFrames with overlapping column names\n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "    df2 = pd.DataFrame({'d': [10, 20, 30], 'c': [40, 50, 60], 'b': [70, 80, 90]})\n",
    "    print df1 + df2\n",
    "\n",
    "# Adding DataFrames with overlapping row indexes\n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]},\n",
    "                       index=['row1', 'row2', 'row3'])\n",
    "    df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]},\n",
    "                       index=['row4', 'row3', 'row2'])\n",
    "    print df1 + df2\n",
    "\n",
    "# --- Quiz ---\n",
    "# Cumulative entries and exits for one station for a few hours.\n",
    "entries_and_exits = pd.DataFrame({\n",
    "    'ENTRIESn': [3144312, 3144335, 3144353, 3144424, 3144594,\n",
    "                 3144808, 3144895, 3144905, 3144941, 3145094],\n",
    "    'EXITSn': [1088151, 1088159, 1088177, 1088231, 1088275,\n",
    "               1088317, 1088328, 1088331, 1088420, 1088753]\n",
    "})\n",
    "\n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits (entries in the first column, exits in the second) and\n",
    "    return a DataFrame with hourly entries and exits (entries in the\n",
    "    first column, exits in the second).\n",
    "    '''    \n",
    "    return entries_and_exits - entries_and_exits.shift(1)\n",
    "\n",
    "print get_hourly_entries_and_exits(entries_and_exits)\n",
    "print entries_and_exits.diff()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.11: DataFrame applymap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        exam1 exam2\n",
      "Andre       F     F\n",
      "Barry       B     D\n",
      "Chris       C     F\n",
      "Dan         C     F\n",
      "Emilio      B     D\n",
      "Fred        C     F\n",
      "Greta       A     C\n",
      "Humbert     D     F\n",
      "Ivan        A     C\n",
      "James       B     D\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame applymap()\n",
    "if False:\n",
    "    df = pd.DataFrame({\n",
    "        'a': [1, 2, 3],\n",
    "        'b': [10, 20, 30],\n",
    "        'c': [5, 10, 15]\n",
    "    })\n",
    "\n",
    "    def add_one(x):\n",
    "        return x + 1\n",
    "\n",
    "    print df.applymap(add_one)\n",
    "    #    a   b   c\n",
    "    # 0  2  11   6\n",
    "    # 1  3  21  11\n",
    "    # 2  4  31  16\n",
    "\n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio',\n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "def convert_grade(grade):\n",
    "    if grade >= 90:\n",
    "        return \"A\"\n",
    "    elif grade >= 80:\n",
    "        return \"B\"\n",
    "    elif grade >= 70:\n",
    "        return \"C\"\n",
    "    elif grade >= 60:\n",
    "        return \"D\"\n",
    "    elif grade >=0:\n",
    "        return \"F\"\n",
    "\n",
    "def convert_grades(grades):\n",
    "    '''\n",
    "    Fill in this function to convert the given DataFrame of numerical\n",
    "    grades to letter grades. Return a new DataFrame with the converted\n",
    "    grade.\n",
    "\n",
    "    The conversion rule is:\n",
    "        90-100 -> A\n",
    "        80-89  -> B\n",
    "        70-79  -> C\n",
    "        60-69  -> D\n",
    "        0-59   -> F\n",
    "    '''\n",
    "    return grades.applymap(convert_grade)\n",
    "\n",
    "print convert_grades(grades_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.12: DataFrame apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andre      F\n",
      "Barry      B\n",
      "Chris      C\n",
      "Dan        C\n",
      "Emilio     B\n",
      "Fred       C\n",
      "Greta      A\n",
      "Humbert    D\n",
      "Ivan       A\n",
      "James      B\n",
      "Name: exam1, dtype: category\n",
      "Categories (5, object): [F < D < C < B < A]\n",
      "            exam1     exam2\n",
      "Andre   -2.315341 -2.304599\n",
      "Barry    0.220191  0.386400\n",
      "Chris    0.020017 -0.096600\n",
      "Dan     -0.180156 -0.096600\n",
      "Emilio   0.753987  0.662400\n",
      "Fred    -0.513779 -0.441600\n",
      "Greta    0.887436  1.490400\n",
      "Humbert -0.847401 -0.786600\n",
      "Ivan     1.354508  1.007400\n",
      "James    0.620538  0.179400\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame apply()\n",
    "if True:\n",
    "    def convert_grades_curve(exam_grades):\n",
    "        # Pandas has a bult-in function that will perform this calculation\n",
    "        # This will give the bottom 0% to 10% of students the grade 'F',\n",
    "        # 10% to 20% the grade 'D', and so on. You can read more about\n",
    "        # the qcut() function here:\n",
    "        # http://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n",
    "        return pd.qcut(exam_grades,\n",
    "                      [0, 0.1, 0.2, 0.5, 0.8, 1],\n",
    "                      labels=['F', 'D', 'C', 'B', 'A'])\n",
    "        \n",
    "    # qcut() operates on a list, array, or Series. This is the\n",
    "    # result of running the function on a single column of the\n",
    "    # DataFrame.\n",
    "    print convert_grades_curve(grades_df['exam1'])\n",
    "    \n",
    "    # qcut() does not work on DataFrames, but we can use apply()\n",
    "    # to call the function on each column separately\n",
    "    # print grades_df.apply(convert_grades_curve)\n",
    "    \n",
    "def standardize_column(column):\n",
    "    standard_deviation = column.std(ddof=0)\n",
    "    mean = column.mean()\n",
    "    return (column - mean)/standard_deviation\n",
    "\n",
    "\n",
    "def standardize(df):\n",
    "    '''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "    '''\n",
    "    return df.apply(standardize_column)\n",
    "    \n",
    "print standardize(grades_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.13: DataFrame apply() Use Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a     3.0\n",
      "b    30.0\n",
      "c    15.0\n",
      "dtype: float64\n",
      "a     5\n",
      "b    50\n",
      "c    25\n",
      "dtype: int64\n",
      "a     4\n",
      "b    40\n",
      "c    20\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': [4, 5, 3, 1, 2],\n",
    "    'b': [20, 10, 40, 50, 30],\n",
    "    'c': [25, 20, 5, 15, 10]\n",
    "})\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# DataFrame apply() - use case 2\n",
    "if True:   \n",
    "    print df.apply(np.mean)\n",
    "    print df.apply(np.max)\n",
    "    \n",
    "def second_largest_in_column(column):\n",
    "    return column.sort_values().iloc[-2]\n",
    "\n",
    "def second_largest(df):\n",
    "    '''\n",
    "    Fill in this function to return the second-largest value of each \n",
    "    column of the input DataFrame.\n",
    "    '''\n",
    "    return df.apply(second_largest_in_column)\n",
    "    \n",
    "print second_largest(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.14: Adding a DataFrame to a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1    2    3\n",
      "0  10  50   90  130\n",
      "1  20  60  100  140\n",
      "2  30  70  110  150\n",
      "3  40  80  120  160\n",
      "\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "dtype: int64\n",
      "\n",
      "    0   1    2    3   4\n",
      "0  11  52   93  134 NaN\n",
      "1  21  62  103  144 NaN\n",
      "2  31  72  113  154 NaN\n",
      "3  41  82  123  164 NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Adding a Series to a square DataFrame\n",
    "if True:\n",
    "    s = pd.Series([1, 2, 3, 4, 5])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print ''\n",
    "    print s\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "# Adding a Series to a one-row DataFrame \n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10], 1: [20], 2: [30], 3: [40]})\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "\n",
    "# Adding a Series to a one-column DataFrame\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({0: [10, 20, 30, 40]})\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "    print df.add(s, axis='index')\n",
    "    \n",
    "# Adding when DataFrame column names match Series index\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "# Adding when DataFrame column names don't match Series index\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3.15: Standardizing Each Column Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            exam1     exam2\n",
      "Andre   -2.315341 -2.304599\n",
      "Barry    0.220191  0.386400\n",
      "Chris    0.020017 -0.096600\n",
      "Dan     -0.180156 -0.096600\n",
      "Emilio   0.753987  0.662400\n",
      "Fred    -0.513779 -0.441600\n",
      "Greta    0.887436  1.490400\n",
      "Humbert -0.847401 -0.786600\n",
      "Ivan     1.354508  1.007400\n",
      "James    0.620538  0.179400 \n",
      "\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Adding using +\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df + s\n",
    "    \n",
    "# Adding with axis='index'\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df.add(s, axis='index')\n",
    "    # The functions sub(), mul(), and div() work similarly to add()\n",
    "    \n",
    "# Adding with axis='columns'\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4])\n",
    "    df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })\n",
    "    \n",
    "    print df\n",
    "    print '' # Create a blank line between outputs\n",
    "    print df.add(s, axis='columns')\n",
    "    # The functions sub(), mul(), and div() work similarly to add()\n",
    "    \n",
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "def standardize(df):\n",
    "    '''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "    \n",
    "    This time, try to use vectorized operations instead of apply().\n",
    "    You should get the same results as you did before.\n",
    "    '''\n",
    "    return (df - df.mean())/df.std(ddof=0)\n",
    "    \n",
    "print standardize(grades_df), '\\n'\n",
    "\n",
    "def standardize_rows(df):\n",
    "    '''\n",
    "    Optional: Fill in this function to standardize each row of the given\n",
    "    DataFrame. Again, try not to use apply().\n",
    "    \n",
    "    This one is more challenging than standardizing each column!\n",
    "    '''\n",
    "    return (df.sub(df.mean(axis=1), axis=0)).div(df.std(ddof=0, axis=1), axis=0)\n",
    "    \n",
    "# print standardize_rows(grades_df)\n",
    "print type(grades_df.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3.16: Pandas groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Axes(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEPCAYAAABMTw/iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112effbd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Examine DataFrame\n",
    "if False:\n",
    "    print example_df\n",
    "    \n",
    "# Examine groups\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    # The groups attribute is a dictionary mapping keys to lists of row indexes\n",
    "    print grouped_data.groups\n",
    "    \n",
    "# Group by multiple columns\n",
    "if False:\n",
    "    grouped_data = example_df.groupby(['even', 'above_three'])\n",
    "    print grouped_data.groups\n",
    "    \n",
    "# Get sum of each group\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print grouped_data.sum()\n",
    "    \n",
    "# Limit columns in result\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    \n",
    "    print '\\n'\n",
    "    # You can take one or more columns from the result DataFrame\n",
    "    print grouped_data.sum()['value']\n",
    "    \n",
    "    print '\\n' # Blank line to separate results\n",
    "    \n",
    "    # You can also take a subset of columns from the grouped data before \n",
    "    # collapsing to a DataFrame. In this case, the result is the same.\n",
    "    print grouped_data['value'].sum()\n",
    "    \n",
    "filename = 'nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "### Write code here to group the subway data by a variable of your choice, then\n",
    "### either print out the mean ridership within each group or create a plot.\n",
    "print subway_df.groupby('day_week').mean()['ENTRIESn'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.17: Calculating Hourly Entries and Exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ENTRIESn  EXITSn\n",
      "0       NaN     NaN\n",
      "1       NaN     NaN\n",
      "2      23.0     8.0\n",
      "3      14.0     8.0\n",
      "4      18.0    18.0\n",
      "5      29.0   205.0\n",
      "6      71.0    54.0\n",
      "7     132.0   593.0\n",
      "8     170.0    44.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Standardize each group\n",
    "if False:\n",
    "    def standardize(xs):\n",
    "        return (xs - xs.mean()) / xs.std()\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print grouped_data['value'].apply(standardize)\n",
    "    \n",
    "# Find second largest value in each group\n",
    "if False:\n",
    "    def second_largest(xs):\n",
    "        sorted_xs = xs.sort_values(inplace=False, ascending=False)\n",
    "        return sorted_xs.iloc[1]\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print grouped_data['value'].apply(second_largest)\n",
    "\n",
    "# --- Quiz ---\n",
    "# DataFrame with cumulative entries and exits for multiple stations\n",
    "ridership_df = pd.DataFrame({\n",
    "    'UNIT': ['R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051'],\n",
    "    'TIMEn': ['00:00:00', '02:00:00', '04:00:00', '06:00:00', '08:00:00', '10:00:00', '12:00:00', '14:00:00', '16:00:00'],\n",
    "    'ENTRIESn': [3144312, 8936644, 3144335, 8936658, 3144353, 8936687, 3144424, 8936819, 3144594],\n",
    "    'EXITSn': [1088151, 13755385,  1088159, 13755393,  1088177, 13755598, 1088231, 13756191,  1088275]\n",
    "})\n",
    "\n",
    "def get_hourly_ridership(column):\n",
    "    return column.diff()\n",
    "    \n",
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits and return a DataFrame with hourly entries and exits.\n",
    "    The hourly entries and exits should be calculated separately for\n",
    "    each station (the 'UNIT' column).\n",
    "    \n",
    "    Hint: Take a look at the `get_hourly_entries_and_exits()` function\n",
    "    you wrote in a previous quiz, DataFrame Vectorized Operations. If\n",
    "    you copy it here and rename it, you can use it and the `.apply()`\n",
    "    function to help solve this problem.\n",
    "    '''\n",
    "\n",
    "    return entries_and_exits.groupby('UNIT')['ENTRIESn', 'EXITSn'].apply(get_hourly_ridership)\n",
    "\n",
    "print get_hourly_entries_and_exits(ridership_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.18: Combining Pandas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DATEn  ENTRIESn    EXITSn  UNIT  hour   latitude  longitude  fog  \\\n",
      "0  05-01-11   4388333   2911002  R003     0  40.689945 -73.872564    0   \n",
      "1  05-02-11   4388348   2911036  R003     0  40.689945 -73.872564    0   \n",
      "2  05-03-11   4389885   2912127  R003     0  40.689945 -73.872564    0   \n",
      "3  05-04-11   4391507   2913223  R003     0  40.689945 -73.872564    0   \n",
      "4  05-05-11   4393043   2914284  R003     0  40.689945 -73.872564    0   \n",
      "5  05-01-11  14656120  14451774  R004     0  40.691320 -73.867135    0   \n",
      "6  05-02-11  14656174  14451851  R004     0  40.691320 -73.867135    0   \n",
      "7  05-03-11  14660126  14454734  R004     0  40.691320 -73.867135    0   \n",
      "8  05-04-11  14664247  14457780  R004     0  40.691320 -73.867135    0   \n",
      "9  05-05-11  14668301  14460818  R004     0  40.691320 -73.867135    0   \n",
      "\n",
      "   pressurei  rain  tempi  wspdi  \n",
      "0      30.24     0   52.0    8.1  \n",
      "1      30.32     0   48.9    6.9  \n",
      "2      30.14     0   54.0    3.5  \n",
      "3      29.98     0   57.2   15.0  \n",
      "4      30.01     0   48.9   15.0  \n",
      "5      30.24     0   52.0    8.1  \n",
      "6      30.32     0   48.9    6.9  \n",
      "7      30.14     0   54.0    3.5  \n",
      "8      29.98     0   57.2   15.0  \n",
      "9      30.01     0   48.9   15.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "subway_df = pd.DataFrame({\n",
    "    'UNIT': ['R003', 'R003', 'R003', 'R003', 'R003', 'R004', 'R004', 'R004',\n",
    "             'R004', 'R004'],\n",
    "    'DATEn': ['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "              '05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'ENTRIESn': [ 4388333,  4388348,  4389885,  4391507,  4393043, 14656120,\n",
    "                 14656174, 14660126, 14664247, 14668301],\n",
    "    'EXITSn': [ 2911002,  2911036,  2912127,  2913223,  2914284, 14451774,\n",
    "               14451851, 14454734, 14457780, 14460818],\n",
    "    'latitude': [ 40.689945,  40.689945,  40.689945,  40.689945,  40.689945,\n",
    "                  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.872564, -73.872564, -73.872564, -73.872564,\n",
    "                  -73.867135, -73.867135, -73.867135, -73.867135, -73.867135]\n",
    "})\n",
    "\n",
    "weather_df = pd.DataFrame({\n",
    "    'DATEn': ['05-01-11', '05-01-11', '05-02-11', '05-02-11', '05-03-11',\n",
    "              '05-03-11', '05-04-11', '05-04-11', '05-05-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'latitude': [ 40.689945,  40.69132 ,  40.689945,  40.69132 ,  40.689945,\n",
    "                  40.69132 ,  40.689945,  40.69132 ,  40.689945,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.867135, -73.872564, -73.867135, -73.872564,\n",
    "                  -73.867135, -73.872564, -73.867135, -73.872564, -73.867135],\n",
    "    'pressurei': [ 30.24,  30.24,  30.32,  30.32,  30.14,  30.14,  29.98,  29.98,\n",
    "                   30.01,  30.01],\n",
    "    'fog': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'rain': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'tempi': [ 52. ,  52. ,  48.9,  48.9,  54. ,  54. ,  57.2,  57.2,  48.9,  48.9],\n",
    "    'wspdi': [  8.1,   8.1,   6.9,   6.9,   3.5,   3.5,  15. ,  15. ,  15. ,  15. ]\n",
    "})\n",
    "\n",
    "def combine_dfs(subway_df, weather_df):\n",
    "    '''\n",
    "    Fill in this function to take 2 DataFrames, one with subway data and one with weather data,\n",
    "    and return a single dataframe with one row for each date, hour, and location. Only include\n",
    "    times and locations that have both subway data and weather data available.\n",
    "    '''\n",
    "    return subway_df.merge(weather_df)\n",
    "    \n",
    "print combine_dfs(subway_df, weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.19: Plotting for Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for this block of code to see what it does\n",
    "\n",
    "# groupby() without as_index\n",
    "if True:\n",
    "    first_even = example_df.groupby('even').first()\n",
    "    print first_even   \n",
    "    print first_even['even'] # Causes an error. 'even' is no longer a column in the DataFrame\n",
    "    \n",
    "# groupby() with as_index=False\n",
    "if False:\n",
    "    first_even = example_df.groupby('even', as_index=False).first()\n",
    "    # print first_even\n",
    "    print first_even['even'] # Now 'even' is still a column in the DataFrame\n",
    "\n",
    "filename = '/datasets/ud170/subway/nyc_subway_weather.csv'\n",
    "subway_df = pd.read_csv(filename)\n",
    "\n",
    "## Make a plot of your choice here showing something interesting about the subway data.\n",
    "## Matplotlib documentation here: http://matplotlib.org/api/pyplot_api.html\n",
    "## Once you've got something you're happy with, share it on the forums!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
